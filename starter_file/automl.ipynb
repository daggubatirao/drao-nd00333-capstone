{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "Import Dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost==0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
   ]
  },
  {
   "source": [
    "Create Compute Cluster : Check if a compute cluster exists. Create a new cluster if a cluster doesn't exist. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amlcompute_cluster_name = \"cluster-capstone\"\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
    "                                                           #vm_priority = 'lowpriority', # optional\n",
    "                                                           min_nodes=1,\n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worlwide.Heart failure is a common event caused by CVDs and this dataset contains 12 features that can be used to predict mortality by heart failure. Most cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol using population-wide strategies.\n",
    "\n",
    "People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.\n",
    "\n",
    "This Heart Failure PRediction dataset is downloaded from Kaggle. Death due to Heart Failure is predicted  using information usch as anaemia, diabetes, high blood pressure, platelets, serum_creatinine, serum_sodium, creatinine_phosporous and ejection_fraction(%bllod leaving the heart at each contraction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = False\n",
    "key = \"HeartFailure Data\"\n",
    "description_text = \"HeartFailure Data from Kaggle\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        dataset = ws.datasets[key] \n",
    "\n",
    "if not found: \n",
    "    # get the datastore to upload prepared data\n",
    "    datastore = ws.get_default_datastore()\n",
    "\n",
    "    # upload the local file from src_dir to the target_path in datastore\n",
    "    datastore.upload(src_dir='data', target_path='data')\n",
    "\n",
    "    # create a dataset referencing the cloud location\n",
    "    dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, ('data/heart_failure_clinical_records_dataset.csv'))])\n",
    "    dataset = dataset.register(workspace=ws, name=\"HeartFailure Data\", description = \"HeartFailure Data from Kaggle\" )\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "Azure Maching Learning support automatic training and comparison of maching learning models using AutoML. To Run AutoML, an AutoMLConfig object needs to be created with paramteres such as dataset, training cluster, machine learning task, target column and metric to evaluate the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\": 2,\n",
    "    \"max_concurrent_iterations\": 10,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "# Put your automl config here\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"DEATH_EVENT\", \n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# choose a name for experiment\n",
    "experiment_name = 'heart-failure-prediction-automl'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "remote_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "source": [
    "The AutoML fitted model can be obtained using the get_output() method of the AutoML run object. The fitted model describes the steps used in the model, the data transformations applied and the hyperparameters used in the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_path='outputs/model.pkl', model_name='automal_heartfailure_prediction_model',\n",
    "                        tags={'Training context':'Auto ML'},\n",
    "                        properties={'AUC': best_run_metrics['AUC_weighted'], 'Accuracy': best_run_metrics['accuracy']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "env = best_run.get_environment()\n",
    "\n",
    "script_file = 'score.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Deploy the model to Azure Container Service, and get the scoring URL from the deployed service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=script_file, environment=env)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                                       memory_gb = 1)\n",
    "\n",
    "deploy_service_name= 'automl-model-deployment'\n",
    "service = Model.deploy(ws,deploy_service_name,  [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "print(\"State: \",service.state)\n",
    "print(\"\\nScoring URI: \", scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Enable logging on the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Enable app insights\n",
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "source": [
    "Test the scoring service using two samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL for the web service, should be similar to:\n",
    "#scoring_uri = 'http://0d469fee-33c0-4ce9-9dac-2767356110c9.southcentralus.azurecontainer.io/score'\n",
    "# If the service is authenticated, set the key or token\n",
    "#key = 'zuv0yY9prOPHFssuYSFWDJPhnVMxgJqG'\n",
    "#two set of data to score, so we get two results back\n",
    "#age,anaemia,creatinine_phosphokinase,diabetes,ejection_fraction,high_blood_pressure,platelets,serum_creatinine,serum_sodium,sex,smoking,time,DEATH_EVENT\n",
    "\n",
    "data = {\"data\": [\n",
    "    {\"age\": 75, \n",
    "     \"anaemia\": 0, \n",
    "     \"creatinine_phosphokinase\": 582, \n",
    "     \"diabetes\": 0, \n",
    "     \"ejection_fraction\": 20, \n",
    "     \"high_blood_pressure\": 1, \n",
    "     \"platelets\": 265000, \n",
    "     \"serum_creatinine\": 1.9, \n",
    "     \"serum_sodium\": 130, \n",
    "     \"sex\": 1, \n",
    "     \"smoking\": 0, \n",
    "     \"time\": 4},\n",
    "\n",
    "    {\"age\": 55, \n",
    "     \"anaemia\": 0, \n",
    "     \"creatinine_phosphokinase\": 7861, \n",
    "     \"diabetes\": 0, \n",
    "     \"ejection_fraction\": 38, \n",
    "     \"high_blood_pressure\": 0, \n",
    "     \"platelets\": 263358.03, \n",
    "     \"serum_creatinine\": 1.1, \n",
    "     \"serum_sodium\": 136, \n",
    "     \"sex\": 1, \n",
    "     \"smoking\": 0, \n",
    "     \"time\": 6},\n",
    "      ]}\n",
    "    \n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "with open(\"data.json\", \"w\") as _f:\n",
    "    _f.write(input_data)\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "#headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())\n",
    "print(\"Case 0: Death, Case 1: Death.\")"
   ]
  },
  {
   "source": [
    "Test the model using two samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"age\": 65, \n",
    "     \"anaemia\": 0, \n",
    "     \"creatinine_phosphokinase\": 146, \n",
    "     \"diabetes\": 0, \n",
    "     \"ejection_fraction\": 20, \n",
    "     \"high_blood_pressure\": 0, \n",
    "     \"platelets\": 162000, \n",
    "     \"serum_creatinine\": 1.3, \n",
    "     \"serum_sodium\": 129, \n",
    "     \"sex\": 1, \n",
    "     \"smoking\": 1, \n",
    "     \"time\": 7},\n",
    "    \n",
    "    {\"age\": 55, \n",
    "     \"anaemia\": 0, \n",
    "     \"creatinine_phosphokinase\": 109, \n",
    "     \"diabetes\": 0, \n",
    "     \"ejection_fraction\": 35, \n",
    "     \"high_blood_pressure\": 0, \n",
    "     \"platelets\": 254000, \n",
    "     \"serum_creatinine\": 1.1, \n",
    "     \"serum_sodium\": 139, \n",
    "     \"sex\": 1, \n",
    "     \"smoking\": 1, \n",
    "     \"time\": 60},\n",
    "      ]\n",
    "    \n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test using service instance\n",
    "input_data = json.dumps({\n",
    "    'data': data\n",
    "})\n",
    "\n",
    "output = service.run(input_data)\n",
    "print(output)\n",
    "print(\"Case 0: Death, Case 1: No Death.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs = service.get_logs()\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}